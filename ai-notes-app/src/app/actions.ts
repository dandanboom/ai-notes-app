"use server";

import { generateObject } from "ai";
import { createGoogleGenerativeAI } from "@ai-sdk/google";
import { z } from "zod";
import * as Diff from "diff";
import type { AIResponse } from "@/types/ai";

// ============================================
// Zod Schema å®šä¹‰ (å†…éƒ¨ä½¿ç”¨ï¼Œä¸å¯¼å‡º)
// ============================================

/**
 * AI å“åº” Schema - ä½¿ç”¨ Zod å®šä¹‰ç»“æ„åŒ–è¾“å‡º
 */
const AIResponseSchema = z.object({
  type: z.enum(["append", "review", "inquire"]).describe(
    "å“åº”ç±»å‹: append=æ–°å¢å†…å®¹, review=ä¿®æ”¹å»ºè®®, inquire=è¿½é—®æ¾„æ¸…"
  ),
  content: z.string().describe(
    "å†…å®¹å­—æ®µ: appendæ¨¡å¼ä¸ºæ–°å¢å†…å®¹, reviewæ¨¡å¼ä¸ºä¿®æ”¹åå®Œæ•´æ®µè½, inquireæ¨¡å¼ä¸ºè¿½é—®é—®é¢˜"
  ),
  userInput: z.string().describe(
    "ç”¨æˆ·è¯´äº†ä»€ä¹ˆ - ç®€æ´å¤è¿°ç”¨æˆ·çš„è¯­éŸ³/æ–‡æœ¬è¾“å…¥"
  ),
  thought: z.string().optional().describe(
    "AI çš„ç®€çŸ­æ€è€ƒè¿‡ç¨‹ï¼Œç”¨äºè°ƒè¯•"
  ),
});

/**
 * è¡Œå†…ç¼–è¾‘ä¸“ç”¨ Schema - Few-Shot Example ç­–ç•¥
 * ç®€åŒ–ä¸ºï¼šè½¬å½• -> åˆ¤æ–­ç±»å‹ -> è¾“å‡ºå†…å®¹
 */
const InlineEditSchema = z.object({
  // Step 1: åŸå§‹è½¬å½•
  transcription: z.string().describe(
    "Step 1: The exact raw transcription of what the user said."
  ),
  // Step 2: ç±»å‹åˆ¤æ–­
  type: z.enum(["append", "review"]).describe(
    "Step 2: If the transcription contains specific keywords like 'Change', 'Delete', 'Replace', 'æ”¹', 'åˆ ', 'æ¢' -> use 'review'. OTHERWISE -> ALWAYS use 'append'."
  ),
  // Step 3: æœ€ç»ˆå†…å®¹
  content: z.string().describe(
    "Step 3: The final text payload. NO questions. NO conversational filler."
  ),
});

// ============================================
// Google AI é…ç½®
// ============================================

const getGoogleAI = () => {
  const apiKey = process.env.GOOGLE_API_KEY;
  if (!apiKey) {
    throw new Error("GOOGLE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ã€‚è¯·åœ¨ Vercel Dashboard â†’ Settings â†’ Environment Variables ä¸­é…ç½®ã€‚");
  }

  let baseURL = process.env.GOOGLE_BASE_URL || "https://generativelanguage.googleapis.com/v1beta";
  const modelId = process.env.GEMINI_MODEL || "gemini-2.0-flash-exp";

  // ç¡®ä¿ baseURL ä»¥ /v1beta ç»“å°¾ï¼ˆç¬¬ä¸‰æ–¹ API éœ€è¦å®Œæ•´è·¯å¾„ï¼‰
  if (!baseURL.includes("/v1beta") && !baseURL.includes("/v1")) {
    baseURL = baseURL.replace(/\/$/, "") + "/v1beta";
  }

  console.log(`ğŸ”§ [AI Config] Base URL: ${baseURL}`);
  console.log(`ğŸ”§ [AI Config] Model: ${modelId}`);
  console.log(`ğŸ”§ [AI Config] API Key: ${apiKey.substring(0, 8)}...`);

  return createGoogleGenerativeAI({
    apiKey,
    baseURL,
  })(modelId);
};

// ============================================
// System Prompts
// ============================================

const GLOBAL_SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„ä¸­æ–‡ç¬”è®°åŠ©æ‰‹ã€‚

## ğŸ¯ æ ¸å¿ƒä»»åŠ¡ï¼šåŒºåˆ†"å£è¿°"å’Œ"æŒ‡ä»¤"

### åˆ¤æ–­è§„åˆ™ï¼ˆæŒ‰é¡ºåºæ£€æŸ¥ï¼‰

**Step 1: æ˜¯å¦åŒ…å«å…·ä½“å†…å®¹ï¼Ÿ**
å¦‚æœç”¨æˆ·çš„è¯ä¸­åŒ…å«ï¼š
- å…·ä½“çš„æ—¶é—´ï¼ˆ3ç‚¹ã€æ˜å¤©ã€ä¸‹å‘¨ä¸€ï¼‰
- å…·ä½“çš„äº‹é¡¹ï¼ˆå¼€ä¼šã€ä¹°èœã€å†™æŠ¥å‘Šï¼‰
- å…·ä½“çš„æ•°æ®ï¼ˆ3ä¸ªä»»åŠ¡ã€100å…ƒã€2å°æ—¶ï¼‰
- æè¿°æ€§å†…å®¹ï¼ˆä»Šå¤©å¾ˆç´¯ã€é¡¹ç›®è¿›å±•é¡ºåˆ©ï¼‰

â†’ **ç›´æ¥è¿”å› type: "append"**ï¼Œå°†å†…å®¹æ•´ç†æˆ Markdown

**Step 2: æ˜¯å¦æ˜¯"ç”Ÿæˆ/åˆ›å»º"ç±»æŒ‡ä»¤ï¼Ÿ**
å…³é”®è¯ï¼šå¸®æˆ‘å†™ã€ç”Ÿæˆä¸€ä¸ªã€åšä¸ªè®¡åˆ’ã€åˆ—ä¸ªæ¸…å•ã€åˆ›å»ºä¸€ä»½

å¦‚æœæ˜¯ï¼Œä¸”**ç¼ºå°‘å…³é”®å‚æ•°**ï¼š
â†’ **è¿”å› type: "inquire"**ï¼Œè¿½é—® 1-2 ä¸ªæ ¸å¿ƒé—®é¢˜

å¦‚æœæ˜¯ï¼Œä¸”**ä¿¡æ¯å·²å……è¶³**ï¼š
â†’ **è¿”å› type: "append"**ï¼Œç›´æ¥ç”Ÿæˆå†…å®¹

**Step 3: æ˜¯å¦æ˜¯"ä¿®æ”¹"ç±»æŒ‡ä»¤ï¼Ÿ**
å…³é”®è¯ï¼šæŠŠè¿™æ®µæ”¹æˆã€ä¿®æ”¹ã€æ¶¦è‰²ã€åˆ æ‰ã€è°ƒæ•´

â†’ **è¿”å› type: "review"**ï¼Œè¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹

## ç¤ºä¾‹åˆ¤æ–­

| ç”¨æˆ·è¯´ | åˆ¤æ–­ | ç±»å‹ |
|-------|------|-----|
| "è®°ä¸€ä¸‹ï¼Œæ˜å¤©ä¸‹åˆ3ç‚¹å¼€ä¼š" | æœ‰å…·ä½“æ—¶é—´å’Œäº‹é¡¹ | append |
| "ä»Šå¤©å®Œæˆäº†ä¸‰ä¸ªä»»åŠ¡ï¼šè°ƒç ”ã€å†™æŠ¥å‘Šã€å¼€ä¼š" | æœ‰å…·ä½“å†…å®¹ | append |
| "å¸®æˆ‘å†™ä¸ªæ—…æ¸¸è®¡åˆ’" | ç”ŸæˆæŒ‡ä»¤ï¼Œç¼ºå°‘å…³é”®ä¿¡æ¯ | inquire |
| "å¸®æˆ‘å†™ä¸ªå»æˆéƒ½2å¤©çš„æ—…æ¸¸è®¡åˆ’" | ç”ŸæˆæŒ‡ä»¤ï¼Œä¿¡æ¯å……è¶³ | append |
| "æŠŠæ—¶é—´æ”¹æˆ4ç‚¹" | ä¿®æ”¹æŒ‡ä»¤ | review |

## ä¸Šä¸‹æ–‡èåˆï¼ˆå½“å­˜åœ¨å¯¹è¯å†å²æ—¶ï¼‰

å½“ç”¨æˆ·åœ¨**å›ç­”è¿½é—®**æ—¶ï¼š
1. å›æº¯å¯¹è¯å†å²ï¼Œæ‰¾åˆ°åŸå§‹éœ€æ±‚
2. åˆå¹¶ï¼šåŸå§‹éœ€æ±‚ + è¡¥å……ä¿¡æ¯
3. ç”Ÿæˆ**å®Œæ•´ä¸°å¯Œ**çš„å†…å®¹ï¼ˆtype: "append"ï¼‰

## è¿½é—®çº¦æŸ

- ä¸€æ¬¡åªé—® **1 ä¸ª**æœ€æ ¸å¿ƒçš„é—®é¢˜
- é—®é¢˜è¦**ç®€çŸ­å£è¯­åŒ–**ï¼ˆå¦‚"å¤§æ¦‚å»å‡ å¤©ï¼Ÿ"ï¼‰
- content **åªæ”¾é—®é¢˜**ï¼Œä¸è¦å®¢å¥—è¯

## é€ƒç”Ÿèˆ±

ç”¨æˆ·è¯´ "éšä¾¿/éƒ½å¯ä»¥/ä½ å®š" â†’ åœæ­¢è¿½é—®ï¼Œç”¨å¸¸è¯†è¡¥å…¨ï¼Œç”Ÿæˆå†…å®¹`;

const INLINE_EDIT_SYSTEM_PROMPT = `You are a background text processing engine. You are NOT a chatbot. You never ask questions.

YOUR GOAL: Process user voice input into Markdown text.

### REFERENCE EXAMPLES (Strictly mimic this behavior)

**CASE 1: Appending new content (Dictation)**
Input Context: "- Buy milk"
User Audio: "And buy eggs"
Output:
{
  "transcription": "And buy eggs",
  "type": "append",
  "content": "- Buy eggs"
}

**CASE 2: Appending with new sentence**
Input Context: "The project is going well."
User Audio: "We need to speed up."
Output:
{
  "transcription": "We need to speed up.",
  "type": "append",
  "content": "We need to speed up."
}

**CASE 3: Specific Edit (Review)**
Input Context: "- Meeting at 3pm"
User Audio: "Change meeting to 4pm"
Output:
{
  "transcription": "Change meeting to 4pm",
  "type": "review",
  "content": "- Meeting at 4pm"
}

**CASE 4: Vague Input (Default to Append)**
Input Context: "TODO List"
User Audio: "Tomorrow"
Output:
{
  "transcription": "Tomorrow",
  "type": "append",
  "content": "- Tomorrow"
}

**CASE 5: Chinese Edit Command**
Input Context: "- 9:00 å¼€ä¼š\\n- 10:00 **å†™ä»£ç **"
User Audio: "æŠŠå†™ä»£ç æ”¹æˆå†™æ–‡æ¡£"
Output:
{
  "transcription": "æŠŠå†™ä»£ç æ”¹æˆå†™æ–‡æ¡£",
  "type": "review",
  "content": "- 9:00 å¼€ä¼š\\n- 10:00 **å†™æ–‡æ¡£**"
}

**CASE 6: Chinese Append**
Input Context: "- 9:00 å¼€ä¼š"
User Audio: "ä¸‹åˆä¸‰ç‚¹å»å¥èº«"
Output:
{
  "transcription": "ä¸‹åˆä¸‰ç‚¹å»å¥èº«",
  "type": "append",
  "content": "- ä¸‹åˆä¸‰ç‚¹å»å¥èº«"
}

### EXECUTION RULES

1. **Transcription First:** Always fill the 'transcription' field with the raw user audio first.
2. **The "Review" Trigger:** Only use 'review' type if the user explicitly says "Change", "Delete", "Remove", "Update", "Replace", "æ”¹", "åˆ ", "æ¢".
3. **The "Append" Default:** For EVERYTHING else (even if it's short, vague, or grammatically incomplete), use 'append'.
4. **Formatting:**
   - If context is a list, format append as a list item (with \`- \`).
   - If context is prose, format append as a sentence.
   - **PRESERVE MARKDOWN** in 'review' mode (bolding, headers).
5. **NO QUESTIONS:** Never output questions like "What do you want to add?" or "ä½ æƒ³æ·»åŠ ä»€ä¹ˆï¼Ÿ"
`;

// ============================================
// å·¥å…·å‡½æ•°
// ============================================

/**
 * å°† File è½¬æ¢ä¸º Base64 Data URL
 */
async function fileToBase64DataURL(file: File): Promise<string> {
  const buffer = await file.arrayBuffer();
  const bytes = new Uint8Array(buffer);
  let binary = "";
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  const base64 = btoa(binary);
  return `data:${file.type};base64,${base64}`;
}

/**
 * ç±»å‹å®ˆå«ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯å­—ç¬¦ä¸²
 * æ³¨æ„ï¼šè¿™ä¸æ˜¯ Server Actionï¼Œä»…ä¾›å†…éƒ¨ä½¿ç”¨
 */
function isErrorResponse(response: unknown): response is string {
  return typeof response === "string" && response.startsWith("ERROR:");
}

// ============================================
// è¯­éŸ³å¤„ç† API
// ============================================

/**
 * å¤„ç†è¯­éŸ³å‘½ä»¤ - ä½¿ç”¨ Vercel AI SDK generateObject
 * 
 * @param formData åŒ…å«éŸ³é¢‘æ–‡ä»¶çš„ FormData
 * @param contextContent å½“å‰æ–‡æ¡£å†…å®¹ï¼ˆç”¨äºè¡Œå†…ç¼–è¾‘ï¼‰
 * @param chatHistory å¯¹è¯å†å²ï¼ˆç”¨äºè¿½é—®åœºæ™¯ï¼‰
 */
export async function processVoiceCommand(
  formData: FormData,
  contextContent?: string,
  chatHistory?: string
): Promise<AIResponse | string> {
  try {
    console.log("ğŸ“¥ [Server Action] æ”¶åˆ°è¯·æ±‚...");

    const audioFile = formData.get("audio") as File;
    if (!audioFile) {
      return "ERROR: æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶";
    }

    console.log(`ğŸ“¦ [Server Action] éŸ³é¢‘: ${audioFile.name}, ${audioFile.size} bytes`);

    if (audioFile.size === 0) {
      return "ERROR: éŸ³é¢‘æ–‡ä»¶ä¸ºç©º";
    }

    // å°†éŸ³é¢‘è½¬ä¸º Data URL
    const audioDataURL = await fileToBase64DataURL(audioFile);

    // åˆ¤æ–­åœºæ™¯
    const hasContext = contextContent && contextContent.trim().length > 0;
    const hasChatHistory = chatHistory && chatHistory.trim().length > 0;
    const isInlineEditMode = hasContext && !hasChatHistory;

    // å‡†å¤‡ Prompt
    let userPrompt: string;
    let systemPrompt: string;
    const schema = isInlineEditMode ? InlineEditSchema : AIResponseSchema;

    if (isInlineEditMode) {
      systemPrompt = INLINE_EDIT_SYSTEM_PROMPT;
      userPrompt = `CONTEXT (ç›®æ ‡æ–‡æœ¬):
\`\`\`markdown
${contextContent}
\`\`\`

TASK: å¬å–éŸ³é¢‘æŒ‡ä»¤ï¼Œç›´æ¥ä¿®æ”¹ä¸Šè¿°æ–‡æœ¬ã€‚ä¸¥ç¦åé—®ã€‚`;
    } else if (hasChatHistory) {
      systemPrompt = GLOBAL_SYSTEM_PROMPT;
      userPrompt = `## å¯¹è¯å†å²

${chatHistory}

## å½“å‰ç¬”è®°ä¸Šä¸‹æ–‡
${hasContext ? contextContent : "(ç©º)"}

## å½“å‰äº¤äº’
ç”¨æˆ·æ­£åœ¨é€šè¿‡è¯­éŸ³å›ç­”ä½ ä¹‹å‰çš„è¿½é—®ã€‚`;
    } else {
      systemPrompt = GLOBAL_SYSTEM_PROMPT;
      userPrompt = hasContext
        ? `ä¸Šä¸‹æ–‡ï¼š\n${contextContent}\n\nç”¨æˆ·æŒ‡ä»¤ï¼šå¬å–è¯­éŸ³å¹¶æ•´ç†æˆ Markdown æ ¼å¼ã€‚`
        : `è¿™æ˜¯ä¸€ä»½æ–°ç¬”è®°ï¼Œè¯·å¬å–ç”¨æˆ·çš„è¯­éŸ³å¹¶æ•´ç†æˆ Markdown æ ¼å¼ã€‚`;
    }

    console.log("ğŸ¤– [Server Action] è°ƒç”¨ Gemini API (generateObject)...");
    console.log("ğŸ“‹ [Server Action] æ¨¡å¼:", isInlineEditMode ? "è¡Œå†…ç¼–è¾‘" : hasChatHistory ? "å¯¹è¯" : "å…¨å±€");

    // è·å–éŸ³é¢‘çš„ MIME ç±»å‹
    const mimeType = audioFile.type || "audio/webm";
    
    // ä½¿ç”¨ generateObject è·å–ç»“æ„åŒ–è¾“å‡º
    const result = await generateObject({
      model: getGoogleAI(),
      schema,
      system: systemPrompt,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "file",
              data: audioDataURL,
              mediaType: mimeType,
            },
            {
              type: "text",
              text: userPrompt,
            },
          ],
        },
      ],
      temperature: isInlineEditMode ? 0.1 : 0.4, // è¡Œå†…ç¼–è¾‘ç”¨ä½æ¸©åº¦ï¼Œé«˜ç¡®å®šæ€§
    });

    const response = result.object;
    console.log("âœ… [Server Action] å®Œæˆ:", response.type, "å†…å®¹é•¿åº¦:", response.content?.length || 0);
    
    // è®°å½•è½¬å½•å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    const transcription = (response as any).transcription || (response as any).userInput;
    if (transcription) {
      console.log("ğŸ¤ [Server Action] è½¬å½•:", transcription);
    }

    // --- è¡Œå†…ç¼–è¾‘æ¨¡å¼ï¼šè®¡ç®—å·®å¼‚é‡ï¼Œå†³å®šæ˜¯å¦è·³è¿‡ Diff è§†å›¾ ---
    if (isInlineEditMode && response.type === "review" && contextContent) {
      const changes = Diff.diffChars(contextContent, response.content || "");
      let changedCharCount = 0;
      
      changes.forEach(part => {
        // ç»Ÿè®¡å¢åŠ æˆ–åˆ é™¤çš„å­—ç¬¦æ•°ï¼ˆä¸ç»Ÿè®¡ä¿æŒä¸å˜çš„ï¼‰
        if (part.added || part.removed) {
          changedCharCount += part.value.length;
        }
      });

      console.log(`ğŸ“Š [Server Action] å˜æ›´å­—ç¬¦æ•°: ${changedCharCount}`);

      // å¦‚æœæ”¹åŠ¨ â‰¤10 ä¸ªå­—ï¼Œé™çº§ä¸º "review_immediate"
      // å‰ç«¯å¯ä»¥æ ¹æ®è¿™ä¸ªæ ‡è®°ç›´æ¥åº”ç”¨ä¿®æ”¹ï¼Œä¸æ˜¾ç¤º Diff å¡ç‰‡
      const shouldSkipDiff = changedCharCount <= 10;
      
      return {
        type: shouldSkipDiff ? "review_immediate" as any : "review",
        content: response.content || "",
        userInput: transcription || "(è¯­éŸ³è¾“å…¥)",
        changedCharCount, // ä¼ é€’ç»™å‰ç«¯ç”¨äºè°ƒè¯•
      };
    }

    // è§„èŒƒåŒ–å“åº”ï¼ˆéè¡Œå†…ç¼–è¾‘æ¨¡å¼æˆ– append ç±»å‹ï¼‰
    return {
      type: response.type as "append" | "review" | "inquire",
      content: response.content || "",
      userInput: transcription || (response as any).userInput || "(è¯­éŸ³è¾“å…¥)",
      thought: (response as any).thought,
    };
  } catch (error: unknown) {
    console.error("âŒ [Server Action] é”™è¯¯:", error);
    
    // è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
    if (error instanceof Error) {
      const errorDetails = {
        message: error.message,
        name: error.name,
        stack: error.stack?.split('\n').slice(0, 3).join('\n'),
        // å°è¯•è·å–æ›´å¤š API é”™è¯¯ä¿¡æ¯
        cause: (error as any).cause,
        response: (error as any).response,
        data: (error as any).data,
      };
      console.error("âŒ [Server Action] é”™è¯¯è¯¦æƒ…:", JSON.stringify(errorDetails, null, 2));
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯ API é…ç½®é”™è¯¯
      if (error.message.includes("API key") || error.message.includes("apiKey")) {
        return "ERROR: API å¯†é’¥æ— æ•ˆæˆ–æœªé…ç½®ã€‚è¯·æ£€æŸ¥ GOOGLE_API_KEY ç¯å¢ƒå˜é‡ã€‚";
      }
      if (error.message.includes("model") || error.message.includes("Model")) {
        return "ERROR: æ¨¡å‹é…ç½®é”™è¯¯ã€‚è¯·æ£€æŸ¥ GEMINI_MODEL ç¯å¢ƒå˜é‡ã€‚";
      }
      if (error.message.includes("fetch") || error.message.includes("network")) {
        return "ERROR: ç½‘ç»œè¿æ¥å¤±è´¥ã€‚è¯·æ£€æŸ¥ GOOGLE_BASE_URL æ˜¯å¦æ­£ç¡®ã€‚";
      }
      if (error.message.includes("Bad Request") || error.message.includes("400")) {
        // è®°å½•å®Œæ•´çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
        console.error("âŒ [Server Action] Bad Request è¯¦æƒ…:", {
          message: error.message,
          cause: (error as any).cause?.message,
          responseBody: (error as any).responseBody,
        });
        return `ERROR: Bad Request - API è¯·æ±‚æ ¼å¼é”™è¯¯ã€‚è¯¦æƒ…: ${error.message}`;
      }
      
      return `ERROR: ${error.message}`;
    }
    return "ERROR: å¤„ç†è¯­éŸ³æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯";
  }
}

// ============================================
// æ–‡æœ¬å¤„ç† API
// ============================================

/**
 * å¤„ç†æ–‡æœ¬å‘½ä»¤ - ä½¿ç”¨ Vercel AI SDK generateObject
 */
export async function processTextCommand(
  text: string,
  contextContent?: string,
  chatHistory?: string
): Promise<AIResponse | string> {
  try {
    console.log("ğŸ’¬ [Server Action] å¤„ç†æ–‡æœ¬:", text.slice(0, 50));

    let userPrompt: string;
    if (chatHistory) {
      userPrompt = `## å®Œæ•´å¯¹è¯å†å²
${chatHistory}

## å½“å‰ç¬”è®°ä¸Šä¸‹æ–‡
${contextContent || "(ç©º)"}

## ç”¨æˆ·æœ€æ–°å›å¤
${text}`;
    } else {
      userPrompt = contextContent
        ? `ä¸Šä¸‹æ–‡ï¼š\n${contextContent}\n\nç”¨æˆ·æŒ‡ä»¤ï¼š${text}`
        : `ç”¨æˆ·æŒ‡ä»¤ï¼š${text}`;
    }

    const result = await generateObject({
      model: getGoogleAI(),
      schema: AIResponseSchema,
      system: GLOBAL_SYSTEM_PROMPT,
      messages: [
        {
          role: "user",
          content: userPrompt,
        },
      ],
      temperature: 0.4,
    });

    const response = result.object;
    return {
      type: response.type,
      content: response.content || "",
      userInput: response.userInput || text,
      thought: response.thought,
    };
  } catch (error) {
    console.error("âŒ [Server Action] æ–‡æœ¬å¤„ç†é”™è¯¯:", error);
    return error instanceof Error ? `ERROR: ${error.message}` : "ERROR: æœªçŸ¥é”™è¯¯";
  }
}

// ============================================
// Ghost Text é¢„æµ‹
// ============================================

/**
 * é¢„æµ‹ Ghost Text (æ™ºèƒ½ç»­å†™)
 */
export async function predictGhostText(currentContext: string): Promise<string> {
  try {
    if (!currentContext || currentContext.trim().length < 5) {
      return "";
    }

    console.log("ğŸ‘» [Ghost Text] é¢„æµ‹ä¸­...");

    const GhostTextSchema = z.object({
      prediction: z.string().describe("é¢„æµ‹çš„ç»­å†™å†…å®¹ï¼Œ1-2å¥è¯"),
    });

    const result = await generateObject({
      model: getGoogleAI(),
      schema: GhostTextSchema,
      system: `ä½ æ˜¯ä¸€ä¸ªæ€ç»´è¡¥å…¨åŠ©æ‰‹ã€‚æ ¹æ®ä¸Šæ–‡é¢„æµ‹ç”¨æˆ·ä¸‹ä¸€å¥æƒ³è¯´çš„è¯ã€‚
è¦æ±‚ï¼š
1. ç®€çŸ­ç²¾ç‚¼ï¼ˆ1-2å¥è¯ï¼‰
2. é€»è¾‘é¡ºç•…æ‰¿æ¥ä¸Šæ–‡
3. åªè¿”å›é¢„æµ‹å†…å®¹ï¼Œä¸è¦è§£é‡Š
4. å¦‚æœéš¾ä»¥é¢„æµ‹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²`,
      messages: [
        {
          role: "user",
          content: `ä¸Šæ–‡ï¼š${currentContext}\n\nè¯·é¢„æµ‹ä¸‹ä¸€å¥ï¼š`,
        },
      ],
      temperature: 0.7,
    });

    const prediction = result.object.prediction?.trim() || "";

    if (prediction.length > 100) {
      return "";
    }

    console.log("ğŸ‘» [Ghost Text] é¢„æµ‹ç»“æœ:", prediction);
    return prediction;
  } catch (error) {
    console.error("âŒ [Ghost Text] é¢„æµ‹å¤±è´¥:", error);
    return "";
  }
}
