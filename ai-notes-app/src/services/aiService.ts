/**
 * AI Service - AI ä¸šåŠ¡é€»è¾‘å±‚
 * 
 * å°è£…æ‰€æœ‰ AI ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
 * å¯è¢« Server Actions å’Œ API Routes å…±åŒè°ƒç”¨
 * 
 * æ³¨æ„ï¼šè¿™ä¸ªæ–‡ä»¶ä¸æ˜¯ Server Actionï¼Œæ²¡æœ‰ "use server" æŒ‡ä»¤
 */

import { generateObject } from "ai";
import { createGoogleGenerativeAI } from "@ai-sdk/google";
import { z } from "zod";
import * as Diff from "diff";
import type { AIResponse } from "@/types/ai";

// ============================================
// ç±»å‹å®šä¹‰
// ============================================

export interface VoiceCommandInput {
  audioDataURL: string;
  mimeType: string;
  contextContent?: string;
  chatHistory?: string;
}

export interface TextCommandInput {
  text: string;
  contextContent?: string;
  chatHistory?: string;
}

export interface GhostTextInput {
  currentContext: string;
}

export type AIServiceResult<T> = 
  | { success: true; data: T }
  | { success: false; error: string };

// ============================================
// Zod Schema å®šä¹‰
// ============================================

/**
 * AI å“åº” Schema - å…¨å±€å¯¹è¯æ¨¡å¼
 */
const AIResponseSchema = z.object({
  type: z.enum(["append", "review", "inquire"]).describe(
    "å“åº”ç±»å‹: append=æ–°å¢å†…å®¹, review=ä¿®æ”¹å»ºè®®, inquire=è¿½é—®æ¾„æ¸…"
  ),
  content: z.string().describe(
    "å†…å®¹å­—æ®µ: appendæ¨¡å¼ä¸ºæ–°å¢å†…å®¹, reviewæ¨¡å¼ä¸ºä¿®æ”¹åå®Œæ•´æ®µè½, inquireæ¨¡å¼ä¸ºè¿½é—®é—®é¢˜"
  ),
  userInput: z.string().describe(
    "ç”¨æˆ·è¯´äº†ä»€ä¹ˆ - ç®€æ´å¤è¿°ç”¨æˆ·çš„è¯­éŸ³/æ–‡æœ¬è¾“å…¥"
  ),
  thought: z.string().optional().describe(
    "AI çš„ç®€çŸ­æ€è€ƒè¿‡ç¨‹ï¼Œç”¨äºè°ƒè¯•"
  ),
});

/**
 * è¡Œå†…ç¼–è¾‘ä¸“ç”¨ Schema - Few-Shot Example ç­–ç•¥
 */
const InlineEditSchema = z.object({
  transcription: z.string().describe(
    "Step 1: The exact raw transcription of what the user said."
  ),
  type: z.enum(["append", "review"]).describe(
    "Step 2: If the transcription contains specific keywords like 'Change', 'Delete', 'Replace', 'æ”¹', 'åˆ ', 'æ¢' -> use 'review'. OTHERWISE -> ALWAYS use 'append'."
  ),
  content: z.string().describe(
    "Step 3: The final text payload. NO questions. NO conversational filler."
  ),
});

/**
 * Ghost Text é¢„æµ‹ Schema
 */
const GhostTextSchema = z.object({
  prediction: z.string().describe("é¢„æµ‹çš„ç»­å†™å†…å®¹ï¼Œ1-2å¥è¯"),
});

// ============================================
// System Prompts
// ============================================

const GLOBAL_SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„ä¸­æ–‡ç¬”è®°åŠ©æ‰‹ã€‚

## ğŸ¯ æ ¸å¿ƒä»»åŠ¡ï¼šåŒºåˆ†"å£è¿°"å’Œ"æŒ‡ä»¤"

### åˆ¤æ–­è§„åˆ™ï¼ˆæŒ‰é¡ºåºæ£€æŸ¥ï¼‰

**Step 1: æ˜¯å¦åŒ…å«å…·ä½“å†…å®¹ï¼Ÿ**
å¦‚æœç”¨æˆ·çš„è¯ä¸­åŒ…å«ï¼š
- å…·ä½“çš„æ—¶é—´ï¼ˆ3ç‚¹ã€æ˜å¤©ã€ä¸‹å‘¨ä¸€ï¼‰
- å…·ä½“çš„äº‹é¡¹ï¼ˆå¼€ä¼šã€ä¹°èœã€å†™æŠ¥å‘Šï¼‰
- å…·ä½“çš„æ•°æ®ï¼ˆ3ä¸ªä»»åŠ¡ã€100å…ƒã€2å°æ—¶ï¼‰
- æè¿°æ€§å†…å®¹ï¼ˆä»Šå¤©å¾ˆç´¯ã€é¡¹ç›®è¿›å±•é¡ºåˆ©ï¼‰

â†’ **ç›´æ¥è¿”å› type: "append"**ï¼Œå°†å†…å®¹æ•´ç†æˆ Markdown

**Step 2: æ˜¯å¦æ˜¯"ç”Ÿæˆ/åˆ›å»º"ç±»æŒ‡ä»¤ï¼Ÿ**
å…³é”®è¯ï¼šå¸®æˆ‘å†™ã€ç”Ÿæˆä¸€ä¸ªã€åšä¸ªè®¡åˆ’ã€åˆ—ä¸ªæ¸…å•ã€åˆ›å»ºä¸€ä»½

å¦‚æœæ˜¯ï¼Œä¸”**ç¼ºå°‘å…³é”®å‚æ•°**ï¼š
â†’ **è¿”å› type: "inquire"**ï¼Œè¿½é—® 1-2 ä¸ªæ ¸å¿ƒé—®é¢˜

å¦‚æœæ˜¯ï¼Œä¸”**ä¿¡æ¯å·²å……è¶³**ï¼š
â†’ **è¿”å› type: "append"**ï¼Œç›´æ¥ç”Ÿæˆå†…å®¹

**Step 3: æ˜¯å¦æ˜¯"ä¿®æ”¹"ç±»æŒ‡ä»¤ï¼Ÿ**
å…³é”®è¯ï¼šæŠŠè¿™æ®µæ”¹æˆã€ä¿®æ”¹ã€æ¶¦è‰²ã€åˆ æ‰ã€è°ƒæ•´

â†’ **è¿”å› type: "review"**ï¼Œè¾“å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹

## ç¤ºä¾‹åˆ¤æ–­

| ç”¨æˆ·è¯´ | åˆ¤æ–­ | ç±»å‹ |
|-------|------|-----|
| "è®°ä¸€ä¸‹ï¼Œæ˜å¤©ä¸‹åˆ3ç‚¹å¼€ä¼š" | æœ‰å…·ä½“æ—¶é—´å’Œäº‹é¡¹ | append |
| "ä»Šå¤©å®Œæˆäº†ä¸‰ä¸ªä»»åŠ¡ï¼šè°ƒç ”ã€å†™æŠ¥å‘Šã€å¼€ä¼š" | æœ‰å…·ä½“å†…å®¹ | append |
| "å¸®æˆ‘å†™ä¸ªæ—…æ¸¸è®¡åˆ’" | ç”ŸæˆæŒ‡ä»¤ï¼Œç¼ºå°‘å…³é”®ä¿¡æ¯ | inquire |
| "å¸®æˆ‘å†™ä¸ªå»æˆéƒ½2å¤©çš„æ—…æ¸¸è®¡åˆ’" | ç”ŸæˆæŒ‡ä»¤ï¼Œä¿¡æ¯å……è¶³ | append |
| "æŠŠæ—¶é—´æ”¹æˆ4ç‚¹" | ä¿®æ”¹æŒ‡ä»¤ | review |

## ä¸Šä¸‹æ–‡èåˆï¼ˆå½“å­˜åœ¨å¯¹è¯å†å²æ—¶ï¼‰

å½“ç”¨æˆ·åœ¨**å›ç­”è¿½é—®**æ—¶ï¼š
1. å›æº¯å¯¹è¯å†å²ï¼Œæ‰¾åˆ°åŸå§‹éœ€æ±‚
2. åˆå¹¶ï¼šåŸå§‹éœ€æ±‚ + è¡¥å……ä¿¡æ¯
3. ç”Ÿæˆ**å®Œæ•´ä¸°å¯Œ**çš„å†…å®¹ï¼ˆtype: "append"ï¼‰

## è¿½é—®çº¦æŸ

- ä¸€æ¬¡åªé—® **1 ä¸ª**æœ€æ ¸å¿ƒçš„é—®é¢˜
- é—®é¢˜è¦**ç®€çŸ­å£è¯­åŒ–**ï¼ˆå¦‚"å¤§æ¦‚å»å‡ å¤©ï¼Ÿ"ï¼‰
- content **åªæ”¾é—®é¢˜**ï¼Œä¸è¦å®¢å¥—è¯

## é€ƒç”Ÿèˆ±

ç”¨æˆ·è¯´ "éšä¾¿/éƒ½å¯ä»¥/ä½ å®š" â†’ åœæ­¢è¿½é—®ï¼Œç”¨å¸¸è¯†è¡¥å…¨ï¼Œç”Ÿæˆå†…å®¹`;

const INLINE_EDIT_SYSTEM_PROMPT = `You are a background text processing engine. You are NOT a chatbot. You never ask questions.

YOUR GOAL: Process user voice input into Markdown text.

### REFERENCE EXAMPLES (Strictly mimic this behavior)

**CASE 1: Appending new content (Dictation)**
Input Context: "- Buy milk"
User Audio: "And buy eggs"
Output:
{
  "transcription": "And buy eggs",
  "type": "append",
  "content": "- Buy eggs"
}

**CASE 2: Appending with new sentence**
Input Context: "The project is going well."
User Audio: "We need to speed up."
Output:
{
  "transcription": "We need to speed up.",
  "type": "append",
  "content": "We need to speed up."
}

**CASE 3: Specific Edit (Review)**
Input Context: "- Meeting at 3pm"
User Audio: "Change meeting to 4pm"
Output:
{
  "transcription": "Change meeting to 4pm",
  "type": "review",
  "content": "- Meeting at 4pm"
}

**CASE 4: Vague Input (Default to Append)**
Input Context: "TODO List"
User Audio: "Tomorrow"
Output:
{
  "transcription": "Tomorrow",
  "type": "append",
  "content": "- Tomorrow"
}

**CASE 5: Chinese Edit Command**
Input Context: "- 9:00 å¼€ä¼š\\n- 10:00 **å†™ä»£ç **"
User Audio: "æŠŠå†™ä»£ç æ”¹æˆå†™æ–‡æ¡£"
Output:
{
  "transcription": "æŠŠå†™ä»£ç æ”¹æˆå†™æ–‡æ¡£",
  "type": "review",
  "content": "- 9:00 å¼€ä¼š\\n- 10:00 **å†™æ–‡æ¡£**"
}

**CASE 6: Chinese Append**
Input Context: "- 9:00 å¼€ä¼š"
User Audio: "ä¸‹åˆä¸‰ç‚¹å»å¥èº«"
Output:
{
  "transcription": "ä¸‹åˆä¸‰ç‚¹å»å¥èº«",
  "type": "append",
  "content": "- ä¸‹åˆä¸‰ç‚¹å»å¥èº«"
}

### EXECUTION RULES

1. **Transcription First:** Always fill the 'transcription' field with the raw user audio first.
2. **The "Review" Trigger:** Only use 'review' type if the user explicitly says "Change", "Delete", "Remove", "Update", "Replace", "æ”¹", "åˆ ", "æ¢".
3. **The "Append" Default:** For EVERYTHING else (even if it's short, vague, or grammatically incomplete), use 'append'.
4. **Formatting:**
   - If context is a list, format append as a list item (with \`- \`).
   - If context is prose, format append as a sentence.
   - **PRESERVE MARKDOWN** in 'review' mode (bolding, headers).
5. **NO QUESTIONS:** Never output questions like "What do you want to add?" or "ä½ æƒ³æ·»åŠ ä»€ä¹ˆï¼Ÿ"
`;

const GHOST_TEXT_SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªæ€ç»´è¡¥å…¨åŠ©æ‰‹ã€‚æ ¹æ®ä¸Šæ–‡é¢„æµ‹ç”¨æˆ·ä¸‹ä¸€å¥æƒ³è¯´çš„è¯ã€‚
è¦æ±‚ï¼š
1. ç®€çŸ­ç²¾ç‚¼ï¼ˆ1-2å¥è¯ï¼‰
2. é€»è¾‘é¡ºç•…æ‰¿æ¥ä¸Šæ–‡
3. åªè¿”å›é¢„æµ‹å†…å®¹ï¼Œä¸è¦è§£é‡Š
4. å¦‚æœéš¾ä»¥é¢„æµ‹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²`;

// ============================================
// Google AI é…ç½®
// ============================================

function getGoogleAI() {
  const apiKey = process.env.GOOGLE_API_KEY;
  if (!apiKey) {
    throw new Error("GOOGLE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®");
  }

  let baseURL = process.env.GOOGLE_BASE_URL || "https://generativelanguage.googleapis.com/v1beta";
  const modelId = process.env.GEMINI_MODEL || "gemini-2.0-flash-exp";

  // ç¡®ä¿ baseURL ä»¥ /v1beta ç»“å°¾
  if (!baseURL.includes("/v1beta") && !baseURL.includes("/v1")) {
    baseURL = baseURL.replace(/\/$/, "") + "/v1beta";
  }

  return createGoogleGenerativeAI({
    apiKey,
    baseURL,
  })(modelId);
}

// ============================================
// æ ¸å¿ƒä¸šåŠ¡æ–¹æ³•
// ============================================

/**
 * å¤„ç†è¯­éŸ³å‘½ä»¤
 * 
 * çº¯ä¸šåŠ¡é€»è¾‘ï¼Œä¸åŒ…å«è®¤è¯
 */
export async function processVoiceCommand(
  input: VoiceCommandInput
): Promise<AIServiceResult<AIResponse>> {
  try {
    const { audioDataURL, mimeType, contextContent, chatHistory } = input;

    // åˆ¤æ–­åœºæ™¯
    const hasContext = contextContent && contextContent.trim().length > 0;
    const hasChatHistory = chatHistory && chatHistory.trim().length > 0;
    const isInlineEditMode = hasContext && !hasChatHistory;

    // å‡†å¤‡ Prompt
    let userPrompt: string;
    let systemPrompt: string;
    const schema = isInlineEditMode ? InlineEditSchema : AIResponseSchema;

    if (isInlineEditMode) {
      systemPrompt = INLINE_EDIT_SYSTEM_PROMPT;
      userPrompt = `CONTEXT (ç›®æ ‡æ–‡æœ¬):
\`\`\`markdown
${contextContent}
\`\`\`

TASK: å¬å–éŸ³é¢‘æŒ‡ä»¤ï¼Œç›´æ¥ä¿®æ”¹ä¸Šè¿°æ–‡æœ¬ã€‚ä¸¥ç¦åé—®ã€‚`;
    } else if (hasChatHistory) {
      systemPrompt = GLOBAL_SYSTEM_PROMPT;
      userPrompt = `## å¯¹è¯å†å²

${chatHistory}

## å½“å‰ç¬”è®°ä¸Šä¸‹æ–‡
${hasContext ? contextContent : "(ç©º)"}

## å½“å‰äº¤äº’
ç”¨æˆ·æ­£åœ¨é€šè¿‡è¯­éŸ³å›ç­”ä½ ä¹‹å‰çš„è¿½é—®ã€‚`;
    } else {
      systemPrompt = GLOBAL_SYSTEM_PROMPT;
      userPrompt = hasContext
        ? `ä¸Šä¸‹æ–‡ï¼š\n${contextContent}\n\nç”¨æˆ·æŒ‡ä»¤ï¼šå¬å–è¯­éŸ³å¹¶æ•´ç†æˆ Markdown æ ¼å¼ã€‚`
        : `è¿™æ˜¯ä¸€ä»½æ–°ç¬”è®°ï¼Œè¯·å¬å–ç”¨æˆ·çš„è¯­éŸ³å¹¶æ•´ç†æˆ Markdown æ ¼å¼ã€‚`;
    }

    console.log("ğŸ¤– [AIService] è°ƒç”¨ Gemini API...");
    console.log("ğŸ“‹ [AIService] æ¨¡å¼:", isInlineEditMode ? "è¡Œå†…ç¼–è¾‘" : hasChatHistory ? "å¯¹è¯" : "å…¨å±€");

    // ä½¿ç”¨ generateObject è·å–ç»“æ„åŒ–è¾“å‡º
    const result = await generateObject({
      model: getGoogleAI(),
      schema,
      system: systemPrompt,
      messages: [
        {
          role: "user",
          content: [
            {
              type: "file",
              data: audioDataURL,
              mediaType: mimeType,
            },
            {
              type: "text",
              text: userPrompt,
            },
          ],
        },
      ],
      temperature: isInlineEditMode ? 0.1 : 0.4,
    });

    const response = result.object;
    console.log("âœ… [AIService] å®Œæˆ:", response.type, "å†…å®¹é•¿åº¦:", response.content?.length || 0);

    const transcription = (response as any).transcription || (response as any).userInput;
    if (transcription) {
      console.log("ğŸ¤ [AIService] è½¬å½•:", transcription);
    }

    // è¡Œå†…ç¼–è¾‘æ¨¡å¼ï¼šè®¡ç®—å·®å¼‚é‡
    if (isInlineEditMode && response.type === "review" && contextContent) {
      const changes = Diff.diffChars(contextContent, response.content || "");
      let changedCharCount = 0;

      changes.forEach(part => {
        if (part.added || part.removed) {
          changedCharCount += part.value.length;
        }
      });

      console.log(`ğŸ“Š [AIService] å˜æ›´å­—ç¬¦æ•°: ${changedCharCount}`);

      const shouldSkipDiff = changedCharCount <= 10;

      return {
        success: true,
        data: {
          type: shouldSkipDiff ? "review_immediate" : "review",
          content: response.content || "",
          userInput: transcription || "(è¯­éŸ³è¾“å…¥)",
          changedCharCount,
        },
      };
    }

    return {
      success: true,
      data: {
        type: response.type as "append" | "review" | "inquire",
        content: response.content || "",
        userInput: transcription || (response as any).userInput || "(è¯­éŸ³è¾“å…¥)",
        thought: (response as any).thought,
      },
    };
  } catch (error) {
    console.error("âŒ [AIService] è¯­éŸ³å¤„ç†é”™è¯¯:", error);
    
    const message = error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯";
    return { success: false, error: message };
  }
}

/**
 * å¤„ç†æ–‡æœ¬å‘½ä»¤
 * 
 * çº¯ä¸šåŠ¡é€»è¾‘ï¼Œä¸åŒ…å«è®¤è¯
 */
export async function processTextCommand(
  input: TextCommandInput
): Promise<AIServiceResult<AIResponse>> {
  try {
    const { text, contextContent, chatHistory } = input;

    let userPrompt: string;
    if (chatHistory) {
      userPrompt = `## å®Œæ•´å¯¹è¯å†å²
${chatHistory}

## å½“å‰ç¬”è®°ä¸Šä¸‹æ–‡
${contextContent || "(ç©º)"}

## ç”¨æˆ·æœ€æ–°å›å¤
${text}`;
    } else {
      userPrompt = contextContent
        ? `ä¸Šä¸‹æ–‡ï¼š\n${contextContent}\n\nç”¨æˆ·æŒ‡ä»¤ï¼š${text}`
        : `ç”¨æˆ·æŒ‡ä»¤ï¼š${text}`;
    }

    const result = await generateObject({
      model: getGoogleAI(),
      schema: AIResponseSchema,
      system: GLOBAL_SYSTEM_PROMPT,
      messages: [
        {
          role: "user",
          content: userPrompt,
        },
      ],
      temperature: 0.4,
    });

    const response = result.object;
    
    return {
      success: true,
      data: {
        type: response.type,
        content: response.content || "",
        userInput: response.userInput || text,
        thought: response.thought,
      },
    };
  } catch (error) {
    console.error("âŒ [AIService] æ–‡æœ¬å¤„ç†é”™è¯¯:", error);
    
    const message = error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯";
    return { success: false, error: message };
  }
}

/**
 * é¢„æµ‹ Ghost Text
 * 
 * çº¯ä¸šåŠ¡é€»è¾‘ï¼Œä¸åŒ…å«è®¤è¯
 */
export async function predictGhostText(
  input: GhostTextInput
): Promise<AIServiceResult<string>> {
  try {
    const { currentContext } = input;

    if (!currentContext || currentContext.trim().length < 5) {
      return { success: true, data: "" };
    }

    console.log("ğŸ‘» [AIService] Ghost Text é¢„æµ‹ä¸­...");

    const result = await generateObject({
      model: getGoogleAI(),
      schema: GhostTextSchema,
      system: GHOST_TEXT_SYSTEM_PROMPT,
      messages: [
        {
          role: "user",
          content: `ä¸Šæ–‡ï¼š${currentContext}\n\nè¯·é¢„æµ‹ä¸‹ä¸€å¥ï¼š`,
        },
      ],
      temperature: 0.7,
    });

    const prediction = result.object.prediction?.trim() || "";

    if (prediction.length > 100) {
      return { success: true, data: "" };
    }

    console.log("ğŸ‘» [AIService] é¢„æµ‹ç»“æœ:", prediction);
    return { success: true, data: prediction };
  } catch (error) {
    console.error("âŒ [AIService] Ghost Text é¢„æµ‹å¤±è´¥:", error);
    return { success: true, data: "" }; // Ghost Text å¤±è´¥ä¸åº”é˜»å¡
  }
}

// ============================================
// å·¥å…·å‡½æ•°ï¼ˆå¯¼å‡ºä¾›å¤–éƒ¨ä½¿ç”¨ï¼‰
// ============================================

/**
 * å°† File è½¬æ¢ä¸º Base64 Data URL
 */
export async function fileToBase64DataURL(file: File): Promise<string> {
  const buffer = await file.arrayBuffer();
  const bytes = new Uint8Array(buffer);
  let binary = "";
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  const base64 = btoa(binary);
  return `data:${file.type};base64,${base64}`;
}
